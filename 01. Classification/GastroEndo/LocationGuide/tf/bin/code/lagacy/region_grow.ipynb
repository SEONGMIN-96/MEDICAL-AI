{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import deque, Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EGD_RegionGrow():\n",
    "    def __init__(self, image: np.array) -> None:\n",
    "        self.image = image\n",
    "        self.gray_image = cv2.cvtColor(self.image, cv2.COLOR_BGR2GRAY)\n",
    "        _, self.binary_image = cv2.threshold(self.gray_image ,25, 255, None)\n",
    "        self.h, self.w =  self.image.shape[:2]\n",
    "    \n",
    "    def apply_region_growing(self):\n",
    "        # 입력 이미지와 동일한 크기의 결과 이미지를 생성하고 모든 픽셀을 0으로 초기화합니다.\n",
    "        segmented = np.zeros_like(self.binary_image)\n",
    "        \n",
    "        # 방문한 픽셀을 추적하기 위한 방문 여부 배열을 생성합니다.\n",
    "        visited = np.zeros((self.h, self.w), dtype=np.uint8)\n",
    "        \n",
    "        seed = self.get_seed_pixel()\n",
    "        \n",
    "        # 영역 색상을 결정하기 위한 시드 픽셀의 색상 값을 가져옵니다.\n",
    "        seed_color = self.binary_image[seed[0], seed[1]]\n",
    "        \n",
    "        # 스택을 사용하여 영역 색칠 작업을 수행합니다.\n",
    "        stack = []\n",
    "        stack.append(seed)\n",
    "               \n",
    "        while len(stack) > 0:\n",
    "            # 스택에서 현재 픽셀을 팝합니다.\n",
    "            current_pixel = stack.pop()\n",
    "            x, y = current_pixel\n",
    "            \n",
    "            # 현재 픽셀을 방문했는지 확인합니다.\n",
    "            if visited[x, y] == 1:\n",
    "                continue\n",
    "            \n",
    "            # 현재 픽셀과 시드 픽셀 사이의 색상 차이를 계산합니다.\n",
    "            pixel_color = self.binary_image[x, y]\n",
    "            color_diff = np.sum(np.abs(pixel_color - seed_color))\n",
    "            \n",
    "            # 같은 색상일 경우 현재 픽셀을 영역에 추가합니다.\n",
    "            if color_diff == 0:\n",
    "                segmented[x, y] = pixel_color\n",
    "                visited[x, y] = 1\n",
    "                \n",
    "                # 현재 픽셀의 이웃 픽셀을 스택에 추가합니다.\n",
    "                if x > 0:\n",
    "                    stack.append((x - 1, y))\n",
    "                if x < self.w - 1:\n",
    "                    stack.append((x + 1, y))\n",
    "                if y > 0:\n",
    "                    stack.append((x, y - 1))\n",
    "                if y < self.h - 1:\n",
    "                    stack.append((x, y + 1))\n",
    "                    \n",
    "        return segmented\n",
    "\n",
    "    def get_seed_pixel(self):\n",
    "        # 통상적으로 위내시경 영상의 roi는 우측에 존재합니다.\n",
    "        # 따라서 우측으로 부터 (0,0)이 아닌 구역을 찾아줍니다.\n",
    "        for i in range(self.w):\n",
    "            if self.binary_image[self.h//2, self.w-(i+1)] == 255:\n",
    "                return (self.h//2, self.w-(i+1))\n",
    "            \n",
    "    def define_roi(self):\n",
    "        # roi 영역으로 유추되는 위치의 x1,x2,y1,y2를 구합니다.\n",
    "        segmented_image = self.apply_region_growing()\n",
    "        \n",
    "        roi = np.where(segmented_image==255)\n",
    "              \n",
    "        y1 = roi[0].max()\n",
    "        y2 = roi[0].min()\n",
    "        x1 = roi[1].max()\n",
    "        x2 = roi[1].min()\n",
    "\n",
    "        return (x1, y1, x2, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_load(path: str):\n",
    "    \"\"\"\n",
    "        \n",
    "    Args:\n",
    "        ...\n",
    "\n",
    "    Return:\n",
    "        ...\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(path)   \n",
    "\n",
    "    # 프레임 길이, 너비/높이, 초당 프레임 수 확인\n",
    "    length = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "    height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    \n",
    "    playback_time = length // fps\n",
    "    playback_time_M = int(playback_time // 60)\n",
    "    playback_time_S = int(playback_time - (playback_time_M * 60))\n",
    "    \n",
    "    print('프레임 길이: %d, 프레임 너비: %d, 프레임 높이: %d, 초당 프레임 수: %d' %(length, width, height, fps))\n",
    "    print('비디어 재생시간: %s:%s' %(str(playback_time_M).zfill(2), str(playback_time_S).zfill(2)))\n",
    "    print('=='*50)\n",
    "    \n",
    "    return cap, {'length':length, 'width': width, 'height': height, 'fps': fps, \n",
    "                    'playback_time': playback_time, 'playback_time_M': playback_time_M, 'playback_time_S': playback_time_S}\n",
    "\n",
    "def crop_frame(frame: None, coord: list, new_width: int, new_height):\n",
    "        \"\"\"\n",
    "            \n",
    "        Args:\n",
    "            ...\n",
    "\n",
    "        Return:\n",
    "            ...\n",
    "        \"\"\"\n",
    "        cut_frame = frame[int(coord[1]):int(coord[3]), int(coord[0]):int(coord[2])]\n",
    "               \n",
    "        croped_frame = cv2.resize(src=cut_frame, \n",
    "                                  dsize=(new_width, new_height))\n",
    "        \n",
    "        croped_frame = croped_frame.reshape(new_width, new_height, 3)\n",
    "        \n",
    "        return frame, croped_frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\data\\encode\\17754773_001.mp4\n",
      "프레임 길이: 4009, 프레임 너비: 1280, 프레임 높이: 720, 초당 프레임 수: 60\n",
      "비디어 재생시간: 01:06\n",
      "====================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\python_ksm\\lib\\site-packages\\ipykernel_launcher.py:35: RuntimeWarning: overflow encountered in ubyte_scalars\n"
     ]
    }
   ],
   "source": [
    "# video_paths = glob.glob(os.path.join('..', 'data', 'encode', '*.mp4'))\n",
    "\n",
    "video_path = os.path.join('..', 'data', 'encode', '17754773_001.mp4')\n",
    "\n",
    "print(video_path)\n",
    "\n",
    "cap, cap_info = video_load(path=video_path)\n",
    "\n",
    "count = 0\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # 더이상 프레임이 존재하지 않을경우 종료\n",
    "    if not ret:\n",
    "        sys.exit()\n",
    "    else:\n",
    "        if count == cap_info['length'] // 60:\n",
    "            # Region Growing 알고리즘을 적용합니다.\n",
    "            exe = EGD_RegionGrow(frame)\n",
    "            \n",
    "            crop_roi = exe.define_roi()\n",
    "            \n",
    "            frame = cv2.rectangle(frame, (crop_roi[0],crop_roi[1]), (crop_roi[2],crop_roi[3]), (0,255,0), 2)\n",
    "            \n",
    "            # # 결과 이미지를 출력합니다.\n",
    "            cv2.imshow('apply roi', frame)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "            \n",
    "            cap.release()\n",
    "                \n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_ksm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "73243b5d4330c2b4bbbfb6ad04d768c2534ec3df9667ff68acbbfcc8ae18633e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

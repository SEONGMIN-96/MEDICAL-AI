{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import helper\n",
    "\n",
    "import torch.nn as nn\n",
    "import torchvision.models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets, models\n",
    "import torchvision.utils\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torchinfo import summary\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor\n",
    "from glob import glob\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from copy import copy\n",
    "from collections import defaultdict\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from torcheval.metrics import BinaryAccuracy\n",
    "import os\n",
    "import torchmetrics\n",
    "import timm\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size=4\n",
    "image_count=50\n",
    "img_size=256\n",
    "tf = ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2170/2170 [04:08<00:00,  8.73it/s]\n"
     ]
    }
   ],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, id,image_list, label_list):\n",
    "        self.img_path = image_list\n",
    "\n",
    "        self.label = label_list\n",
    "        self.id=id\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        id_tensor=self.id[idx]\n",
    "        image_tensor = self.img_path[idx]\n",
    "    \n",
    "        label_tensor =  self.label[idx]\n",
    "        return image_tensor, label_tensor\n",
    "\n",
    "\n",
    "train_data=pd.read_csv('../../data/train.csv',encoding='cp949') \n",
    "file_path='../../data/frame/'\n",
    "train_image_list=[]\n",
    "for i in range(len(train_data)):\n",
    "    file_name=train_data.loc[i]['FileName']\n",
    "    id=file_name[:file_name.find('_')]\n",
    "    train_image_list.append(file_path+id)\n",
    "label_data=pd.read_csv('../../data/label_data.csv',encoding='cp949')  \n",
    "train_label_list=[]\n",
    "train_id_list=[]\n",
    "train_image_tensor = torch.empty((len(train_image_list),image_count,3, img_size, img_size))\n",
    "for i in tqdm(range(len(train_image_list))):\n",
    "    folder_name=os.path.basename(train_image_list[i])\n",
    "    dst_label=label_data.loc[label_data['일련번호']==int(folder_name[:-1])]\n",
    "    dst_label=dst_label.loc[dst_label['구분값']==int(folder_name[-1])].reset_index()\n",
    "    label=int(dst_label.loc[0]['OTE 원인'])\n",
    "    train_id_list.append(folder_name)\n",
    "    train_label_list.append(label-1) \n",
    "    image_file_list = glob(train_image_list[i]+'/*.jpg')\n",
    "    if len(image_file_list)>image_count:\n",
    "        image_index = torch.randint(low=0, high=len(\n",
    "            image_file_list)-image_count, size=(1,))\n",
    "        count = 0\n",
    "        for index in range(image_count):\n",
    "            image = 1-tf(Image.open(image_file_list[index]).resize((img_size,img_size)))\n",
    "            train_image_tensor[i,count] = image\n",
    "            count += 1\n",
    "    else:\n",
    "        count = 0\n",
    "        for index in range(len(image_file_list)):\n",
    "            image = 1-tf(Image.open(image_file_list[index]).resize((img_size,img_size)))\n",
    "            train_image_tensor[i,count] = image\n",
    "            count += 1\n",
    "        for j in range(image_count-count):\n",
    "            image = 1-tf(Image.open(image_file_list[j]).resize((img_size,img_size)))\n",
    "            train_image_tensor[i,count] = image\n",
    "            count += 1\n",
    "            \n",
    "\n",
    "train_dataset = CustomDataset(train_id_list,train_image_tensor, F.one_hot(torch.tensor(train_label_list).to(torch.int64)))\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=========================================================================================================\n",
       "Layer (type:depth-idx)                                  Output Shape              Param #\n",
       "=========================================================================================================\n",
       "AttentionMILModel                                       [4, 3]                    --\n",
       "├─FeatureExtractor: 1-1                                 [200, 1408]               --\n",
       "│    └─Sequential: 2-1                                  [200, 1408]               --\n",
       "│    │    └─Conv2d: 3-1                                 [200, 32, 128, 128]       864\n",
       "│    │    └─BatchNormAct2d: 3-2                         [200, 32, 128, 128]       64\n",
       "│    │    └─Sequential: 3-3                             [200, 352, 8, 8]          7,201,634\n",
       "│    │    └─Conv2d: 3-4                                 [200, 1408, 8, 8]         495,616\n",
       "│    │    └─BatchNormAct2d: 3-5                         [200, 1408, 8, 8]         2,816\n",
       "│    │    └─SelectAdaptivePool2d: 3-6                   [200, 1408]               --\n",
       "├─Sequential: 1-2                                       [4, 50, 1]                --\n",
       "│    └─Linear: 2-2                                      [4, 50, 128]              180,352\n",
       "│    └─Tanh: 2-3                                        [4, 50, 128]              --\n",
       "│    └─Linear: 2-4                                      [4, 50, 1]                129\n",
       "├─Dropout: 1-3                                          [4, 1408]                 --\n",
       "├─Linear: 1-4                                           [4, 3]                    4,227\n",
       "=========================================================================================================\n",
       "Total params: 7,885,702\n",
       "Trainable params: 7,885,702\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 171.69\n",
       "=========================================================================================================\n",
       "Input size (MB): 157.29\n",
       "Forward/backward pass size (MB): 20488.48\n",
       "Params size (MB): 31.27\n",
       "Estimated Total Size (MB): 20677.04\n",
       "========================================================================================================="
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class FeatureExtractor(nn.Module):\n",
    "    \"\"\"Feature extoractor block\"\"\"\n",
    "    def __init__(self):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        cnn1= timm.create_model('efficientnet_b2', pretrained=True)\n",
    "        self.feature_ex = nn.Sequential(*list(cnn1.children())[:-1])\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        features = self.feature_ex(inputs)\n",
    "        \n",
    "        return features\n",
    "    \n",
    "class AttentionMILModel(nn.Module):\n",
    "    def __init__(self, num_classes, image_feature_dim,feature_extractor_scale1: FeatureExtractor):\n",
    "        super(AttentionMILModel, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.image_feature_dim = image_feature_dim\n",
    "\n",
    "        # Remove the classification head of the CNN model\n",
    "        self.feature_extractor = feature_extractor_scale1\n",
    "        \n",
    "        # Attention mechanism\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(image_feature_dim, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "        \n",
    "        # Classification layer\n",
    "        self.classification_layer = nn.Linear(image_feature_dim, num_classes)\n",
    "        self.dropout=torch.nn.Dropout(0.2)\n",
    "    def forward(self, inputs):\n",
    "        batch_size, num_tiles, channels, height, width = inputs.size()\n",
    "        \n",
    "        # Flatten the inputs\n",
    "        inputs = inputs.view(-1, channels, height, width)\n",
    "        \n",
    "        # Feature extraction using the pre-trained CNN\n",
    "        features = self.feature_extractor(inputs)  # Shape: (batch_size * num_tiles, 2048, 1, 1)\n",
    "        \n",
    "        # Reshape features\n",
    "        features = features.view(batch_size, num_tiles, -1)  # Shape: (batch_size, num_tiles, 2048)\n",
    "        \n",
    "        # Attention mechanism\n",
    "        attention_weights = self.attention(features)  # Shape: (batch_size, num_tiles, 1)\n",
    "        attention_weights = F.softmax(attention_weights, dim=1)  # Normalize attention weights\n",
    "        \n",
    "        # Apply attention weights to features\n",
    "        attended_features = torch.sum(features * attention_weights, dim=1)  # Shape: (batch_size, 2048)\n",
    "        attended_features=self.dropout(attended_features)\n",
    "        attended_features=F.relu(attended_features)\n",
    "        # Classification layer\n",
    "        logits = self.classification_layer(attended_features)  # Shape: (batch_size, num_classes)\n",
    "        \n",
    "        return logits\n",
    "Feature_Extractor=FeatureExtractor()\n",
    "model = AttentionMILModel(3,1408,Feature_Extractor)\n",
    "model = model.to(device)\n",
    "accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=3).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=2e-4)\n",
    "summary(model,(batch_size,image_count,3,img_size,img_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[deeplearning Start]\n",
      "deeplearning Start Time : 2023-12-19 11:49:20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 1/50 Step: 70 loss : 1.0096 accuracy: 0.5362:  13%|█▎        | 69/542 [00:30<03:27,  2.28it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 31\u001b[0m\n\u001b[1;32m     29\u001b[0m cost\u001b[38;5;241m.\u001b[39mbackward() \u001b[38;5;66;03m# cost에 대한 backward 구함\u001b[39;00m\n\u001b[1;32m     30\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep() \n\u001b[0;32m---> 31\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mcost\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m acc_loss\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39macc\n\u001b[1;32m     33\u001b[0m train\u001b[38;5;241m.\u001b[39mset_description(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;241m50\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Step: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcount\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m loss : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrunning_loss\u001b[38;5;241m/\u001b[39mcount\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc_loss\u001b[38;5;241m/\u001b[39mcount\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "d = datetime.datetime.now()\n",
    "now_time = f\"{d.year}-{d.month}-{d.day} {d.hour}:{d.minute}:{d.second}\"\n",
    "print(f'[deeplearning Start]')\n",
    "print(f'deeplearning Start Time : {now_time}')\n",
    "MIN_loss=5000\n",
    "train_loss_list=[]\n",
    "val_loss_list=[]\n",
    "train_acc_list=[]\n",
    "sig=nn.Sigmoid()\n",
    "val_acc_list=[]\n",
    "MIN_acc=0\n",
    "\n",
    "for epoch in range(50):\n",
    "    train=tqdm(train_dataloader)\n",
    "    count=0\n",
    "    running_loss = 0.0\n",
    "    acc_loss=0\n",
    "    model.train()\n",
    "    for x, y in train:\n",
    "        \n",
    "        y = y.to(device).float()\n",
    "        count+=1\n",
    "        x=x.to(device).float()\n",
    "        optimizer.zero_grad()  # optimizer zero 로 초기화\n",
    "        predict = model(x).to(device)\n",
    "        cost = F.cross_entropy(predict.softmax(dim=1), y) # cost 구함\n",
    "        acc=accuracy(predict.softmax(dim=1).argmax(dim=1),y.argmax(dim=1))\n",
    "        cost.backward() # cost에 대한 backward 구함\n",
    "        optimizer.step() \n",
    "        running_loss += cost.item()\n",
    "        acc_loss+=acc\n",
    "        train.set_description(f\"epoch: {epoch+1}/{50} Step: {count+1} loss : {running_loss/count:.4f} accuracy: {acc_loss/count:.4f}\")\n",
    "    train_loss_list.append((running_loss/count))\n",
    "    train_acc_list.append((acc_loss/count).cpu().detach().numpy())   \n",
    "        \n",
    "torch.save(model.state_dict(), '../../model/attention_eff50_MIL.pt')\n",
    "end = time.time()\n",
    "d = datetime.datetime.now()\n",
    "now_time = f\"{d.year}-{d.month}-{d.day} {d.hour}:{d.minute}:{d.second}\"\n",
    "print(f'deeplearning Time : {now_time}s Time taken : {start-end}')\n",
    "print(f'[deeplearning End]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[deeplearning Start]\n",
      " deeplearning Start Time : 2023-12-19 11:49:20\n",
      " epoch: 1/50 Step: 541 loss : 1.0194 accuracy: 0.4986: 100%|██████████| 540/540 [03:54<00:00,  2.30it/s]\n",
      " Validation epoch: 1/50 Step: 68 loss : 1.0451  accuracy: 0.4888: 100%|██████████| 67/67 [00:09<00:00,  7.20it/s]\n",
      " epoch: 2/50 Step: 541 loss : 0.9950 accuracy: 0.5347: 100%|██████████| 540/540 [03:55<00:00,  2.29it/s]\n",
      " Validation epoch: 2/50 Step: 68 loss : 0.9870  accuracy: 0.5373: 100%|██████████| 67/67 [00:09<00:00,  7.12it/s]\n",
      " epoch: 3/50 Step: 541 loss : 0.9734 accuracy: 0.5519: 100%|██████████| 540/540 [03:55<00:00,  2.29it/s]\n",
      " Validation epoch: 3/50 Step: 68 loss : 1.0056  accuracy: 0.5112: 100%|██████████| 67/67 [00:09<00:00,  7.07it/s]\n",
      " epoch: 4/50 Step: 541 loss : 0.9608 accuracy: 0.5644: 100%|██████████| 540/540 [03:56<00:00,  2.29it/s]\n",
      " Validation epoch: 4/50 Step: 68 loss : 0.9889  accuracy: 0.5410: 100%|██████████| 67/67 [00:09<00:00,  7.09it/s]\n",
      " epoch: 5/50 Step: 541 loss : 0.9481 accuracy: 0.5870: 100%|██████████| 540/540 [03:56<00:00,  2.29it/s]\n",
      " Validation epoch: 5/50 Step: 68 loss : 1.0009  accuracy: 0.5224: 100%|██████████| 67/67 [00:09<00:00,  7.14it/s]\n",
      " epoch: 6/50 Step: 541 loss : 0.9228 accuracy: 0.6153: 100%|██████████| 540/540 [03:55<00:00,  2.29it/s]\n",
      " Validation epoch: 6/50 Step: 68 loss : 0.9926  accuracy: 0.5261: 100%|██████████| 67/67 [00:09<00:00,  7.04it/s]\n",
      " epoch: 7/50 Step: 541 loss : 0.9114 accuracy: 0.6250: 100%|██████████| 540/540 [03:55<00:00,  2.29it/s]\n",
      " Validation epoch: 7/50 Step: 68 loss : 0.9841  accuracy: 0.5597: 100%|██████████| 67/67 [00:09<00:00,  7.21it/s]\n",
      " epoch: 8/50 Step: 541 loss : 0.8868 accuracy: 0.6500: 100%|██████████| 540/540 [03:55<00:00,  2.29it/s]\n",
      " Validation epoch: 8/50 Step: 68 loss : 0.9845  accuracy: 0.5448: 100%|██████████| 67/67 [00:09<00:00,  7.30it/s]\n",
      " epoch: 9/50 Step: 541 loss : 0.8699 accuracy: 0.6750: 100%|██████████| 540/540 [03:57<00:00,  2.28it/s]\n",
      " Validation epoch: 9/50 Step: 68 loss : 0.9889  accuracy: 0.5485: 100%|██████████| 67/67 [00:09<00:00,  6.87it/s]\n",
      " epoch: 10/50 Step: 541 loss : 0.8592 accuracy: 0.6801: 100%|██████████| 540/540 [03:55<00:00,  2.29it/s]\n",
      " Validation epoch: 10/50 Step: 68 loss : 0.9609  accuracy: 0.5634: 100%|██████████| 67/67 [00:09<00:00,  6.91it/s]\n",
      " epoch: 11/50 Step: 541 loss : 0.8371 accuracy: 0.7088: 100%|██████████| 540/540 [03:55<00:00,  2.29it/s]\n",
      " Validation epoch: 11/50 Step: 68 loss : 0.9256  accuracy: 0.6157: 100%|██████████| 67/67 [00:09<00:00,  6.97it/s]\n",
      " epoch: 12/50 Step: 541 loss : 0.8125 accuracy: 0.7315: 100%|██████████| 540/540 [03:55<00:00,  2.29it/s]\n",
      " Validation epoch: 12/50 Step: 68 loss : 0.9574  accuracy: 0.6314: 100%|██████████| 67/67 [00:09<00:00,  7.20it/s]\n",
      " epoch: 13/50 Step: 541 loss : 0.7927 accuracy: 0.7532: 100%|██████████| 540/540 [03:54<00:00,  2.30it/s]\n",
      " Validation epoch: 13/50 Step: 68 loss : 0.9104  accuracy: 0.6811: 100%|██████████| 67/67 [00:09<00:00,  7.23it/s]\n",
      " epoch: 14/50 Step: 541 loss : 0.7842 accuracy: 0.7634: 100%|██████████| 540/540 [03:54<00:00,  2.30it/s]\n",
      " Validation epoch: 14/50 Step: 68 loss : 0.8651  accuracy: 0.7311: 100%|██████████| 67/67 [00:09<00:00,  7.14it/s]\n",
      " epoch: 15/50 Step: 541 loss : 0.7696 accuracy: 0.7759: 100%|██████████| 540/540 [03:55<00:00,  2.30it/s]\n",
      " Validation epoch: 15/50 Step: 68 loss : 0.8251  accuracy: 0.7631: 100%|██████████| 67/67 [00:09<00:00,  7.16it/s]\n",
      " epoch: 16/50 Step: 541 loss : 0.7455 accuracy: 0.8046: 100%|██████████| 540/540 [03:54<00:00,  2.30it/s]\n",
      " Validation epoch: 16/50 Step: 68 loss : 0.9970  accuracy: 0.5485: 100%|██████████| 67/67 [00:09<00:00,  7.24it/s]\n",
      " epoch: 17/50 Step: 541 loss : 0.7392 accuracy: 0.8088: 100%|██████████| 540/540 [03:54<00:00,  2.30it/s]\n",
      " Validation epoch: 17/50 Step: 68 loss : 0.9877  accuracy: 0.5522: 100%|██████████| 67/67 [00:09<00:00,  7.24it/s]\n",
      " epoch: 18/50 Step: 541 loss : 0.7401 accuracy: 0.8065: 100%|██████████| 540/540 [03:54<00:00,  2.30it/s]\n",
      " Validation epoch: 18/50 Step: 68 loss : 1.0150  accuracy: 0.5261: 100%|██████████| 67/67 [00:09<00:00,  7.26it/s]\n",
      " epoch: 19/50 Step: 541 loss : 0.7204 accuracy: 0.8245: 100%|██████████| 540/540 [03:53<00:00,  2.31it/s]\n",
      " Validation epoch: 19/50 Step: 68 loss : 0.9656  accuracy: 0.5709: 100%|██████████| 67/67 [00:09<00:00,  7.40it/s]\n",
      " epoch: 20/50 Step: 541 loss : 0.7171 accuracy: 0.8347: 100%|██████████| 540/540 [03:53<00:00,  2.31it/s]\n",
      " Validation epoch: 20/50 Step: 68 loss : 0.9911  accuracy: 0.5485: 100%|██████████| 67/67 [00:09<00:00,  6.82it/s]\n",
      " epoch: 21/50 Step: 541 loss : 0.7015 accuracy: 0.8444: 100%|██████████| 540/540 [03:54<00:00,  2.30it/s]\n",
      " Validation epoch: 21/50 Step: 68 loss : 0.9824  accuracy: 0.5522: 100%|██████████| 67/67 [00:09<00:00,  6.91it/s]\n",
      " epoch: 22/50 Step: 541 loss : 0.7131 accuracy: 0.8338: 100%|██████████| 540/540 [03:53<00:00,  2.32it/s]\n",
      " Validation epoch: 22/50 Step: 68 loss : 0.9565  accuracy: 0.5858: 100%|██████████| 67/67 [00:09<00:00,  7.03it/s]\n",
      " epoch: 23/50 Step: 541 loss : 0.6749 accuracy: 0.8750: 100%|██████████| 540/540 [03:55<00:00,  2.30it/s]\n",
      " Validation epoch: 23/50 Step: 68 loss : 0.9797  accuracy: 0.5560: 100%|██████████| 67/67 [00:08<00:00,  7.54it/s]\n",
      " epoch: 24/50 Step: 541 loss : 0.6771 accuracy: 0.8727: 100%|██████████| 540/540 [03:53<00:00,  2.32it/s]\n",
      " Validation epoch: 24/50 Step: 68 loss : 1.0148  accuracy: 0.5299: 100%|██████████| 67/67 [00:09<00:00,  6.96it/s]\n",
      " epoch: 25/50 Step: 541 loss : 0.6908 accuracy: 0.8556: 100%|██████████| 540/540 [03:56<00:00,  2.28it/s]\n",
      " Validation epoch: 25/50 Step: 68 loss : 0.9950  accuracy: 0.5410: 100%|██████████| 67/67 [00:09<00:00,  7.02it/s]\n",
      " epoch: 26/50 Step: 541 loss : 0.6729 accuracy: 0.8755: 100%|██████████| 540/540 [03:57<00:00,  2.27it/s]\n",
      " Validation epoch: 26/50 Step: 68 loss : 0.9782  accuracy: 0.5634: 100%|██████████| 67/67 [00:09<00:00,  6.93it/s]\n",
      " epoch: 27/50 Step: 541 loss : 0.6877 accuracy: 0.8620: 100%|██████████| 540/540 [03:55<00:00,  2.29it/s]\n",
      " Validation epoch: 27/50 Step: 68 loss : 1.0036  accuracy: 0.5410: 100%|██████████| 67/67 [00:09<00:00,  6.73it/s]\n",
      " epoch: 28/50 Step: 541 loss : 0.6672 accuracy: 0.8824: 100%|██████████| 540/540 [03:58<00:00,  2.26it/s]\n",
      " Validation epoch: 28/50 Step: 68 loss : 0.9632  accuracy: 0.5784: 100%|██████████| 67/67 [00:09<00:00,  6.88it/s]\n",
      " epoch: 29/50 Step: 541 loss : 0.6572 accuracy: 0.8944: 100%|██████████| 540/540 [03:53<00:00,  2.31it/s]\n",
      " Validation epoch: 29/50 Step: 68 loss : 0.9418  accuracy: 0.6045: 100%|██████████| 67/67 [00:09<00:00,  7.44it/s]\n",
      " epoch: 30/50 Step: 541 loss : 0.6500 accuracy: 0.9019: 100%|██████████| 540/540 [03:53<00:00,  2.31it/s]\n",
      " Validation epoch: 30/50 Step: 68 loss : 0.9713  accuracy: 0.5597: 100%|██████████| 67/67 [00:09<00:00,  7.38it/s]\n",
      " epoch: 31/50 Step: 541 loss : 0.6631 accuracy: 0.8884: 100%|██████████| 540/540 [03:53<00:00,  2.32it/s]\n",
      " Validation epoch: 31/50 Step: 68 loss : 0.9853  accuracy: 0.5560: 100%|██████████| 67/67 [00:09<00:00,  6.77it/s]\n",
      " epoch: 32/50 Step: 541 loss : 0.6592 accuracy: 0.8903: 100%|██████████| 540/540 [03:57<00:00,  2.27it/s]\n",
      " Validation epoch: 32/50 Step: 68 loss : 0.9734  accuracy: 0.5746: 100%|██████████| 67/67 [00:09<00:00,  7.23it/s]\n",
      " epoch: 33/50 Step: 541 loss : 0.6482 accuracy: 0.9019: 100%|██████████| 540/540 [03:56<00:00,  2.28it/s]\n",
      " Validation epoch: 33/50 Step: 68 loss : 0.9545  accuracy: 0.5858: 100%|██████████| 67/67 [00:09<00:00,  7.24it/s]\n",
      " epoch: 34/50 Step: 541 loss : 0.6462 accuracy: 0.9032: 100%|██████████| 540/540 [03:58<00:00,  2.26it/s]\n",
      " Validation epoch: 34/50 Step: 68 loss : 1.0065  accuracy: 0.5299: 100%|██████████| 67/67 [00:09<00:00,  7.02it/s]\n",
      " epoch: 35/50 Step: 541 loss : 0.6382 accuracy: 0.9102: 100%|██████████| 540/540 [03:58<00:00,  2.26it/s]\n",
      " Validation epoch: 35/50 Step: 68 loss : 0.9724  accuracy: 0.5672: 100%|██████████| 67/67 [00:09<00:00,  7.29it/s]\n",
      " epoch: 36/50 Step: 541 loss : 0.6667 accuracy: 0.8829: 100%|██████████| 540/540 [03:57<00:00,  2.28it/s]\n",
      " Validation epoch: 36/50 Step: 68 loss : 1.0007  accuracy: 0.5336: 100%|██████████| 67/67 [00:09<00:00,  6.89it/s]\n",
      " epoch: 37/50 Step: 541 loss : 0.6635 accuracy: 0.8884: 100%|██████████| 540/540 [03:56<00:00,  2.28it/s]\n",
      " Validation epoch: 37/50 Step: 68 loss : 1.0118  accuracy: 0.5299: 100%|██████████| 67/67 [00:10<00:00,  6.60it/s]\n",
      " epoch: 38/50 Step: 541 loss : 0.6532 accuracy: 0.8977: 100%|██████████| 540/540 [03:56<00:00,  2.29it/s]\n",
      " Validation epoch: 38/50 Step: 68 loss : 0.9783  accuracy: 0.5709: 100%|██████████| 67/67 [00:09<00:00,  6.79it/s]\n",
      " epoch: 39/50 Step: 541 loss : 0.6474 accuracy: 0.9019: 100%|██████████| 540/540 [03:56<00:00,  2.28it/s]\n",
      " Validation epoch: 39/50 Step: 68 loss : 1.0232  accuracy: 0.5187: 100%|██████████| 67/67 [00:09<00:00,  6.90it/s]\n",
      " epoch: 40/50 Step: 541 loss : 0.6399 accuracy: 0.9106: 100%|██████████| 540/540 [03:56<00:00,  2.28it/s]\n",
      " Validation epoch: 40/50 Step: 68 loss : 0.9822  accuracy: 0.5522: 100%|██████████| 67/67 [00:09<00:00,  6.80it/s]\n",
      " epoch: 41/50 Step: 541 loss : 0.6173 accuracy: 0.9329: 100%|██████████| 540/540 [03:56<00:00,  2.28it/s]\n",
      " Validation epoch: 41/50 Step: 68 loss : 0.9794  accuracy: 0.5672: 100%|██████████| 67/67 [00:09<00:00,  6.88it/s]\n",
      " epoch: 42/50 Step: 541 loss : 0.6143 accuracy: 0.9384: 100%|██████████| 540/540 [03:55<00:00,  2.29it/s]\n",
      " Validation epoch: 42/50 Step: 68 loss : 1.0212  accuracy: 0.5075: 100%|██████████| 67/67 [00:08<00:00,  7.49it/s]\n",
      " epoch: 43/50 Step: 541 loss : 0.6568 accuracy: 0.8921: 100%|██████████| 540/540 [03:53<00:00,  2.31it/s]\n",
      " Validation epoch: 43/50 Step: 68 loss : 0.9951  accuracy: 0.5448: 100%|██████████| 67/67 [00:09<00:00,  6.80it/s]\n",
      " epoch: 44/50 Step: 541 loss : 0.6470 accuracy: 0.9032: 100%|██████████| 540/540 [03:58<00:00,  2.27it/s]\n",
      " Validation epoch: 44/50 Step: 68 loss : 1.0129  accuracy: 0.5224: 100%|██████████| 67/67 [00:09<00:00,  6.91it/s]\n",
      " epoch: 45/50 Step: 541 loss : 0.6378 accuracy: 0.9111: 100%|██████████| 540/540 [03:57<00:00,  2.28it/s]\n",
      " Validation epoch: 45/50 Step: 68 loss : 1.0036  accuracy: 0.5448: 100%|██████████| 67/67 [00:09<00:00,  6.85it/s]\n",
      " epoch: 46/50 Step: 541 loss : 0.6272 accuracy: 0.9231: 100%|██████████| 540/540 [03:57<00:00,  2.27it/s]\n",
      " Validation epoch: 46/50 Step: 68 loss : 1.0143  accuracy: 0.5224: 100%|██████████| 67/67 [00:09<00:00,  6.86it/s]\n",
      " epoch: 47/50 Step: 541 loss : 0.6255 accuracy: 0.9250: 100%|██████████| 540/540 [03:56<00:00,  2.28it/s]\n",
      " Validation epoch: 47/50 Step: 68 loss : 0.9707  accuracy: 0.5746: 100%|██████████| 67/67 [00:09<00:00,  6.86it/s]\n",
      " epoch: 48/50 Step: 541 loss : 0.6298 accuracy: 0.9194: 100%|██████████| 540/540 [03:57<00:00,  2.28it/s]\n",
      " Validation epoch: 48/50 Step: 68 loss : 1.0366  accuracy: 0.5000: 100%|██████████| 67/67 [00:09<00:00,  6.78it/s]\n",
      " epoch: 49/50 Step: 541 loss : 0.6384 accuracy: 0.9106: 100%|██████████| 540/540 [03:57<00:00,  2.27it/s]\n",
      " Validation epoch: 49/50 Step: 68 loss : 1.0164  accuracy: 0.5336: 100%|██████████| 67/67 [00:09<00:00,  6.88it/s]\n",
      " epoch: 50/50 Step: 541 loss : 0.6367 accuracy: 0.9120: 100%|██████████| 540/540 [03:56<00:00,  2.29it/s]\n",
      " Validation epoch: 50/50 Step: 68 loss : 1.0553  accuracy: 0.4776: 100%|██████████| 67/67 [00:09<00:00,  6.78it/s]\n",
      " deeplearning Time : 2023-12-19 15:14:38 Time taken : 12276.459565162659\n",
      " [deeplearning End]\n"
     ]
    }
   ],
   "source": [
    "print('[deeplearning Start]\\n \\\n",
    "deeplearning Start Time : 2023-12-19 11:49:20\\n \\\n",
    "epoch: 1/50 Step: 541 loss : 1.0194 accuracy: 0.4986: 100%|██████████| 540/540 [03:54<00:00,  2.30it/s]\\n \\\n",
    "Validation epoch: 1/50 Step: 68 loss : 1.0451  accuracy: 0.4888: 100%|██████████| 67/67 [00:09<00:00,  7.20it/s]\\n \\\n",
    "epoch: 2/50 Step: 541 loss : 0.9950 accuracy: 0.5347: 100%|██████████| 540/540 [03:55<00:00,  2.29it/s]\\n \\\n",
    "Validation epoch: 2/50 Step: 68 loss : 0.9870  accuracy: 0.5373: 100%|██████████| 67/67 [00:09<00:00,  7.12it/s]\\n \\\n",
    "epoch: 3/50 Step: 541 loss : 0.9734 accuracy: 0.5519: 100%|██████████| 540/540 [03:55<00:00,  2.29it/s]\\n \\\n",
    "Validation epoch: 3/50 Step: 68 loss : 1.0056  accuracy: 0.5112: 100%|██████████| 67/67 [00:09<00:00,  7.07it/s]\\n \\\n",
    "epoch: 4/50 Step: 541 loss : 0.9608 accuracy: 0.5644: 100%|██████████| 540/540 [03:56<00:00,  2.29it/s]\\n \\\n",
    "Validation epoch: 4/50 Step: 68 loss : 0.9889  accuracy: 0.5410: 100%|██████████| 67/67 [00:09<00:00,  7.09it/s]\\n \\\n",
    "epoch: 5/50 Step: 541 loss : 0.9481 accuracy: 0.5870: 100%|██████████| 540/540 [03:56<00:00,  2.29it/s]\\n \\\n",
    "Validation epoch: 5/50 Step: 68 loss : 1.0009  accuracy: 0.5224: 100%|██████████| 67/67 [00:09<00:00,  7.14it/s]\\n \\\n",
    "epoch: 6/50 Step: 541 loss : 0.9228 accuracy: 0.6153: 100%|██████████| 540/540 [03:55<00:00,  2.29it/s]\\n \\\n",
    "Validation epoch: 6/50 Step: 68 loss : 0.9926  accuracy: 0.5261: 100%|██████████| 67/67 [00:09<00:00,  7.04it/s]\\n \\\n",
    "epoch: 7/50 Step: 541 loss : 0.9114 accuracy: 0.6250: 100%|██████████| 540/540 [03:55<00:00,  2.29it/s]\\n \\\n",
    "Validation epoch: 7/50 Step: 68 loss : 0.9841  accuracy: 0.5597: 100%|██████████| 67/67 [00:09<00:00,  7.21it/s]\\n \\\n",
    "epoch: 8/50 Step: 541 loss : 0.8868 accuracy: 0.6500: 100%|██████████| 540/540 [03:55<00:00,  2.29it/s]\\n \\\n",
    "Validation epoch: 8/50 Step: 68 loss : 0.9845  accuracy: 0.5448: 100%|██████████| 67/67 [00:09<00:00,  7.30it/s]\\n \\\n",
    "epoch: 9/50 Step: 541 loss : 0.8699 accuracy: 0.6750: 100%|██████████| 540/540 [03:57<00:00,  2.28it/s]\\n \\\n",
    "Validation epoch: 9/50 Step: 68 loss : 0.9889  accuracy: 0.5485: 100%|██████████| 67/67 [00:09<00:00,  6.87it/s]\\n \\\n",
    "epoch: 10/50 Step: 541 loss : 0.8592 accuracy: 0.6801: 100%|██████████| 540/540 [03:55<00:00,  2.29it/s]\\n \\\n",
    "Validation epoch: 10/50 Step: 68 loss : 0.9609  accuracy: 0.5634: 100%|██████████| 67/67 [00:09<00:00,  6.91it/s]\\n \\\n",
    "epoch: 11/50 Step: 541 loss : 0.8371 accuracy: 0.7088: 100%|██████████| 540/540 [03:55<00:00,  2.29it/s]\\n \\\n",
    "Validation epoch: 11/50 Step: 68 loss : 0.9256  accuracy: 0.6157: 100%|██████████| 67/67 [00:09<00:00,  6.97it/s]\\n \\\n",
    "epoch: 12/50 Step: 541 loss : 0.8125 accuracy: 0.7315: 100%|██████████| 540/540 [03:55<00:00,  2.29it/s]\\n \\\n",
    "Validation epoch: 12/50 Step: 68 loss : 0.9574  accuracy: 0.6314: 100%|██████████| 67/67 [00:09<00:00,  7.20it/s]\\n \\\n",
    "epoch: 13/50 Step: 541 loss : 0.7927 accuracy: 0.7532: 100%|██████████| 540/540 [03:54<00:00,  2.30it/s]\\n \\\n",
    "Validation epoch: 13/50 Step: 68 loss : 0.9104  accuracy: 0.6811: 100%|██████████| 67/67 [00:09<00:00,  7.23it/s]\\n \\\n",
    "epoch: 14/50 Step: 541 loss : 0.7842 accuracy: 0.7634: 100%|██████████| 540/540 [03:54<00:00,  2.30it/s]\\n \\\n",
    "Validation epoch: 14/50 Step: 68 loss : 0.8651  accuracy: 0.7311: 100%|██████████| 67/67 [00:09<00:00,  7.14it/s]\\n \\\n",
    "epoch: 15/50 Step: 541 loss : 0.7696 accuracy: 0.7759: 100%|██████████| 540/540 [03:55<00:00,  2.30it/s]\\n \\\n",
    "Validation epoch: 15/50 Step: 68 loss : 0.8251  accuracy: 0.7631: 100%|██████████| 67/67 [00:09<00:00,  7.16it/s]\\n \\\n",
    "epoch: 16/50 Step: 541 loss : 0.7455 accuracy: 0.8046: 100%|██████████| 540/540 [03:54<00:00,  2.30it/s]\\n \\\n",
    "Validation epoch: 16/50 Step: 68 loss : 0.9970  accuracy: 0.5485: 100%|██████████| 67/67 [00:09<00:00,  7.24it/s]\\n \\\n",
    "epoch: 17/50 Step: 541 loss : 0.7392 accuracy: 0.8088: 100%|██████████| 540/540 [03:54<00:00,  2.30it/s]\\n \\\n",
    "Validation epoch: 17/50 Step: 68 loss : 0.9877  accuracy: 0.5522: 100%|██████████| 67/67 [00:09<00:00,  7.24it/s]\\n \\\n",
    "epoch: 18/50 Step: 541 loss : 0.7401 accuracy: 0.8065: 100%|██████████| 540/540 [03:54<00:00,  2.30it/s]\\n \\\n",
    "Validation epoch: 18/50 Step: 68 loss : 1.0150  accuracy: 0.5261: 100%|██████████| 67/67 [00:09<00:00,  7.26it/s]\\n \\\n",
    "epoch: 19/50 Step: 541 loss : 0.7204 accuracy: 0.8245: 100%|██████████| 540/540 [03:53<00:00,  2.31it/s]\\n \\\n",
    "Validation epoch: 19/50 Step: 68 loss : 0.9656  accuracy: 0.5709: 100%|██████████| 67/67 [00:09<00:00,  7.40it/s]\\n \\\n",
    "epoch: 20/50 Step: 541 loss : 0.7171 accuracy: 0.8347: 100%|██████████| 540/540 [03:53<00:00,  2.31it/s]\\n \\\n",
    "Validation epoch: 20/50 Step: 68 loss : 0.9911  accuracy: 0.5485: 100%|██████████| 67/67 [00:09<00:00,  6.82it/s]\\n \\\n",
    "epoch: 21/50 Step: 541 loss : 0.7015 accuracy: 0.8444: 100%|██████████| 540/540 [03:54<00:00,  2.30it/s]\\n \\\n",
    "Validation epoch: 21/50 Step: 68 loss : 0.9824  accuracy: 0.5522: 100%|██████████| 67/67 [00:09<00:00,  6.91it/s]\\n \\\n",
    "epoch: 22/50 Step: 541 loss : 0.7131 accuracy: 0.8338: 100%|██████████| 540/540 [03:53<00:00,  2.32it/s]\\n \\\n",
    "Validation epoch: 22/50 Step: 68 loss : 0.9565  accuracy: 0.5858: 100%|██████████| 67/67 [00:09<00:00,  7.03it/s]\\n \\\n",
    "epoch: 23/50 Step: 541 loss : 0.6749 accuracy: 0.8750: 100%|██████████| 540/540 [03:55<00:00,  2.30it/s]\\n \\\n",
    "Validation epoch: 23/50 Step: 68 loss : 0.9797  accuracy: 0.5560: 100%|██████████| 67/67 [00:08<00:00,  7.54it/s]\\n \\\n",
    "epoch: 24/50 Step: 541 loss : 0.6771 accuracy: 0.8727: 100%|██████████| 540/540 [03:53<00:00,  2.32it/s]\\n \\\n",
    "Validation epoch: 24/50 Step: 68 loss : 1.0148  accuracy: 0.5299: 100%|██████████| 67/67 [00:09<00:00,  6.96it/s]\\n \\\n",
    "epoch: 25/50 Step: 541 loss : 0.6908 accuracy: 0.8556: 100%|██████████| 540/540 [03:56<00:00,  2.28it/s]\\n \\\n",
    "Validation epoch: 25/50 Step: 68 loss : 0.9950  accuracy: 0.5410: 100%|██████████| 67/67 [00:09<00:00,  7.02it/s]\\n \\\n",
    "epoch: 26/50 Step: 541 loss : 0.6729 accuracy: 0.8755: 100%|██████████| 540/540 [03:57<00:00,  2.27it/s]\\n \\\n",
    "Validation epoch: 26/50 Step: 68 loss : 0.9782  accuracy: 0.5634: 100%|██████████| 67/67 [00:09<00:00,  6.93it/s]\\n \\\n",
    "epoch: 27/50 Step: 541 loss : 0.6877 accuracy: 0.8620: 100%|██████████| 540/540 [03:55<00:00,  2.29it/s]\\n \\\n",
    "Validation epoch: 27/50 Step: 68 loss : 1.0036  accuracy: 0.5410: 100%|██████████| 67/67 [00:09<00:00,  6.73it/s]\\n \\\n",
    "epoch: 28/50 Step: 541 loss : 0.6672 accuracy: 0.8824: 100%|██████████| 540/540 [03:58<00:00,  2.26it/s]\\n \\\n",
    "Validation epoch: 28/50 Step: 68 loss : 0.9632  accuracy: 0.5784: 100%|██████████| 67/67 [00:09<00:00,  6.88it/s]\\n \\\n",
    "epoch: 29/50 Step: 541 loss : 0.6572 accuracy: 0.8944: 100%|██████████| 540/540 [03:53<00:00,  2.31it/s]\\n \\\n",
    "Validation epoch: 29/50 Step: 68 loss : 0.9418  accuracy: 0.6045: 100%|██████████| 67/67 [00:09<00:00,  7.44it/s]\\n \\\n",
    "epoch: 30/50 Step: 541 loss : 0.6500 accuracy: 0.9019: 100%|██████████| 540/540 [03:53<00:00,  2.31it/s]\\n \\\n",
    "Validation epoch: 30/50 Step: 68 loss : 0.9713  accuracy: 0.5597: 100%|██████████| 67/67 [00:09<00:00,  7.38it/s]\\n \\\n",
    "epoch: 31/50 Step: 541 loss : 0.6631 accuracy: 0.8884: 100%|██████████| 540/540 [03:53<00:00,  2.32it/s]\\n \\\n",
    "Validation epoch: 31/50 Step: 68 loss : 0.9853  accuracy: 0.5560: 100%|██████████| 67/67 [00:09<00:00,  6.77it/s]\\n \\\n",
    "epoch: 32/50 Step: 541 loss : 0.6592 accuracy: 0.8903: 100%|██████████| 540/540 [03:57<00:00,  2.27it/s]\\n \\\n",
    "Validation epoch: 32/50 Step: 68 loss : 0.9734  accuracy: 0.5746: 100%|██████████| 67/67 [00:09<00:00,  7.23it/s]\\n \\\n",
    "epoch: 33/50 Step: 541 loss : 0.6482 accuracy: 0.9019: 100%|██████████| 540/540 [03:56<00:00,  2.28it/s]\\n \\\n",
    "Validation epoch: 33/50 Step: 68 loss : 0.9545  accuracy: 0.5858: 100%|██████████| 67/67 [00:09<00:00,  7.24it/s]\\n \\\n",
    "epoch: 34/50 Step: 541 loss : 0.6462 accuracy: 0.9032: 100%|██████████| 540/540 [03:58<00:00,  2.26it/s]\\n \\\n",
    "Validation epoch: 34/50 Step: 68 loss : 1.0065  accuracy: 0.5299: 100%|██████████| 67/67 [00:09<00:00,  7.02it/s]\\n \\\n",
    "epoch: 35/50 Step: 541 loss : 0.6382 accuracy: 0.9102: 100%|██████████| 540/540 [03:58<00:00,  2.26it/s]\\n \\\n",
    "Validation epoch: 35/50 Step: 68 loss : 0.9724  accuracy: 0.5672: 100%|██████████| 67/67 [00:09<00:00,  7.29it/s]\\n \\\n",
    "epoch: 36/50 Step: 541 loss : 0.6667 accuracy: 0.8829: 100%|██████████| 540/540 [03:57<00:00,  2.28it/s]\\n \\\n",
    "Validation epoch: 36/50 Step: 68 loss : 1.0007  accuracy: 0.5336: 100%|██████████| 67/67 [00:09<00:00,  6.89it/s]\\n \\\n",
    "epoch: 37/50 Step: 541 loss : 0.6635 accuracy: 0.8884: 100%|██████████| 540/540 [03:56<00:00,  2.28it/s]\\n \\\n",
    "Validation epoch: 37/50 Step: 68 loss : 1.0118  accuracy: 0.5299: 100%|██████████| 67/67 [00:10<00:00,  6.60it/s]\\n \\\n",
    "epoch: 38/50 Step: 541 loss : 0.6532 accuracy: 0.8977: 100%|██████████| 540/540 [03:56<00:00,  2.29it/s]\\n \\\n",
    "Validation epoch: 38/50 Step: 68 loss : 0.9783  accuracy: 0.5709: 100%|██████████| 67/67 [00:09<00:00,  6.79it/s]\\n \\\n",
    "epoch: 39/50 Step: 541 loss : 0.6474 accuracy: 0.9019: 100%|██████████| 540/540 [03:56<00:00,  2.28it/s]\\n \\\n",
    "Validation epoch: 39/50 Step: 68 loss : 1.0232  accuracy: 0.5187: 100%|██████████| 67/67 [00:09<00:00,  6.90it/s]\\n \\\n",
    "epoch: 40/50 Step: 541 loss : 0.6399 accuracy: 0.9106: 100%|██████████| 540/540 [03:56<00:00,  2.28it/s]\\n \\\n",
    "Validation epoch: 40/50 Step: 68 loss : 0.9822  accuracy: 0.5522: 100%|██████████| 67/67 [00:09<00:00,  6.80it/s]\\n \\\n",
    "epoch: 41/50 Step: 541 loss : 0.6173 accuracy: 0.9329: 100%|██████████| 540/540 [03:56<00:00,  2.28it/s]\\n \\\n",
    "Validation epoch: 41/50 Step: 68 loss : 0.9794  accuracy: 0.5672: 100%|██████████| 67/67 [00:09<00:00,  6.88it/s]\\n \\\n",
    "epoch: 42/50 Step: 541 loss : 0.6143 accuracy: 0.9384: 100%|██████████| 540/540 [03:55<00:00,  2.29it/s]\\n \\\n",
    "Validation epoch: 42/50 Step: 68 loss : 1.0212  accuracy: 0.5075: 100%|██████████| 67/67 [00:08<00:00,  7.49it/s]\\n \\\n",
    "epoch: 43/50 Step: 541 loss : 0.6568 accuracy: 0.8921: 100%|██████████| 540/540 [03:53<00:00,  2.31it/s]\\n \\\n",
    "Validation epoch: 43/50 Step: 68 loss : 0.9951  accuracy: 0.5448: 100%|██████████| 67/67 [00:09<00:00,  6.80it/s]\\n \\\n",
    "epoch: 44/50 Step: 541 loss : 0.6470 accuracy: 0.9032: 100%|██████████| 540/540 [03:58<00:00,  2.27it/s]\\n \\\n",
    "Validation epoch: 44/50 Step: 68 loss : 1.0129  accuracy: 0.5224: 100%|██████████| 67/67 [00:09<00:00,  6.91it/s]\\n \\\n",
    "epoch: 45/50 Step: 541 loss : 0.6378 accuracy: 0.9111: 100%|██████████| 540/540 [03:57<00:00,  2.28it/s]\\n \\\n",
    "Validation epoch: 45/50 Step: 68 loss : 1.0036  accuracy: 0.5448: 100%|██████████| 67/67 [00:09<00:00,  6.85it/s]\\n \\\n",
    "epoch: 46/50 Step: 541 loss : 0.6272 accuracy: 0.9231: 100%|██████████| 540/540 [03:57<00:00,  2.27it/s]\\n \\\n",
    "Validation epoch: 46/50 Step: 68 loss : 1.0143  accuracy: 0.5224: 100%|██████████| 67/67 [00:09<00:00,  6.86it/s]\\n \\\n",
    "epoch: 47/50 Step: 541 loss : 0.6255 accuracy: 0.9250: 100%|██████████| 540/540 [03:56<00:00,  2.28it/s]\\n \\\n",
    "Validation epoch: 47/50 Step: 68 loss : 0.9707  accuracy: 0.5746: 100%|██████████| 67/67 [00:09<00:00,  6.86it/s]\\n \\\n",
    "epoch: 48/50 Step: 541 loss : 0.6298 accuracy: 0.9194: 100%|██████████| 540/540 [03:57<00:00,  2.28it/s]\\n \\\n",
    "Validation epoch: 48/50 Step: 68 loss : 1.0366  accuracy: 0.5000: 100%|██████████| 67/67 [00:09<00:00,  6.78it/s]\\n \\\n",
    "epoch: 49/50 Step: 541 loss : 0.6384 accuracy: 0.9106: 100%|██████████| 540/540 [03:57<00:00,  2.27it/s]\\n \\\n",
    "Validation epoch: 49/50 Step: 68 loss : 1.0164  accuracy: 0.5336: 100%|██████████| 67/67 [00:09<00:00,  6.88it/s]\\n \\\n",
    "epoch: 50/50 Step: 541 loss : 0.6367 accuracy: 0.9120: 100%|██████████| 540/540 [03:56<00:00,  2.29it/s]\\n \\\n",
    "Validation epoch: 50/50 Step: 68 loss : 1.0553  accuracy: 0.4776: 100%|██████████| 67/67 [00:09<00:00,  6.78it/s]\\n \\\n",
    "deeplearning Time : 2023-12-19 15:14:38 Time taken : 12276.459565162659\\n \\\n",
    "[deeplearning End]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7311)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.sigmoid(torch.tensor(1))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import f1_score\n",
    "cm = confusion_matrix(total_y.cpu().argmax(axis=1),total_prob.cpu().argmax(axis=1))\n",
    "classes = ['Oropharynx','Tonguebase','Epiglottis']\n",
    "\n",
    "cm_display = ConfusionMatrixDisplay(cm,\n",
    "                              display_labels=classes).plot()\n",
    "f1 = f1_score(total_y.cpu().argmax(axis=1),total_prob.cpu().argmax(axis=1), average='macro')\n",
    "\n",
    "print(f'total f1-score= {f1}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getIntersection_Method2(a, b):\n",
    "    indices = torch.zeros_like(a, dtype=torch.uint8)\n",
    "\n",
    "    for elem in b:\n",
    "        indices = indices | (a == elem).type(torch.uint8)\n",
    "\n",
    "    intersection = a[indices.type(torch.bool)]\n",
    "    return intersection\n",
    "\n",
    "def dfaa(index,name_list,label_clip,path_list):\n",
    "    for i in range(len(index)):\n",
    "        id=path_list[index[i]][0]\n",
    "        temp_label=label_clip.loc[label_clip['wake']==int(id[-1])]\n",
    "        temp_label=temp_label.loc[temp_label['Serial Number']==int(id[:-1])]\n",
    "        temp_label=temp_label.reset_index()\n",
    "        file_name=temp_label.loc[0]['File Name']\n",
    "        name_list.append(file_name)\n",
    "    return name_list\n",
    "    \n",
    "y_label=total_y.cpu().argmax(axis=1)\n",
    "prob_label=total_prob.cpu().argmax(axis=1)\n",
    "\n",
    "label_clip=pd.read_csv('../../data/label.csv',encoding='cp949') \n",
    "file_name_list=[]\n",
    "index_1_1=getIntersection_Method2(torch.where(y_label==0)[0],torch.where(prob_label==0)[0])[:76]\n",
    "index_1_2=getIntersection_Method2(torch.where(y_label==0)[0],torch.where(prob_label==1)[0])[:18]\n",
    "index_1_3=getIntersection_Method2(torch.where(y_label==0)[0],torch.where(prob_label==2)[0])[:3]\n",
    "index_2_1=getIntersection_Method2(torch.where(y_label==1)[0],torch.where(prob_label==0)[0])[:24]\n",
    "index_2_2=getIntersection_Method2(torch.where(y_label==1)[0],torch.where(prob_label==1)[0])[:96]\n",
    "index_2_3=getIntersection_Method2(torch.where(y_label==1)[0],torch.where(prob_label==2)[0])[:6]\n",
    "index_3_1=getIntersection_Method2(torch.where(y_label==2)[0],torch.where(prob_label==0)[0])[:7]\n",
    "index_3_2=getIntersection_Method2(torch.where(y_label==2)[0],torch.where(prob_label==1)[0])[:10]\n",
    "index_3_3=getIntersection_Method2(torch.where(y_label==2)[0],torch.where(prob_label==2)[0])[:31]\n",
    "\n",
    "file_name_list=dfaa(index_1_1,file_name_list,label_clip,path_list)\n",
    "file_name_list=dfaa(index_1_2,file_name_list,label_clip,path_list)\n",
    "file_name_list=dfaa(index_1_3,file_name_list,label_clip,path_list)\n",
    "file_name_list=dfaa(index_2_1,file_name_list,label_clip,path_list)\n",
    "file_name_list=dfaa(index_2_2,file_name_list,label_clip,path_list)\n",
    "file_name_list=dfaa(index_2_3,file_name_list,label_clip,path_list)\n",
    "file_name_list=dfaa(index_3_1,file_name_list,label_clip,path_list)\n",
    "file_name_list=dfaa(index_3_2,file_name_list,label_clip,path_list)\n",
    "file_name_list=dfaa(index_3_3,file_name_list,label_clip,path_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(file_name_list).to_csv('../../data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('../../data/test.csv',encoding='cp949') \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LeeYS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
